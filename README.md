## DocInsights

talk to documents using local LLM with the power of RAG

# Installation
````
pip install requirements.txt
curl -fsSL https://ollama.com/install.sh | sh
ollama serve
````
--in a seperate window--
````
ollama pull phi3
streamlit run streamlit_app.py
````
